#!/usr/bin/env python3
"""
æœ€æ–°ãƒ‡ãƒ¼ã‚¿å¯¾å¿œæ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ + æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ã€æœ€é«˜æ€§èƒ½ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰
"""

import pandas as pd
import numpy as np
import xgboost as xgb
import lightgbm as lgb
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, roc_auc_score, classification_report
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
import glob
import os
import joblib
from datetime import datetime

class LatestDataMLSystem:
    def __init__(self):
        self.models = {}
        self.feature_importance = {}
        self.results = {}
        self.feature_names = []
        
    def load_all_data(self):
        """æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ + æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆã—ã¦èª­ã¿è¾¼ã¿"""
        print("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹...")
        
        # 1. æ—¢å­˜CSVãƒ‡ãƒ¼ã‚¿
        csv_files = sorted(glob.glob('csv/m*.csv'))
        
        # 2. æœ€æ–°å–å¾—ãƒ‡ãƒ¼ã‚¿
        latest_files = sorted(glob.glob('latest_data/*.csv'))
        
        print(f"æ—¢å­˜CSVãƒ•ã‚¡ã‚¤ãƒ«: {len(csv_files)}å€‹")
        print(f"æœ€æ–°ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«: {len(latest_files)}å€‹")
        
        all_dfs = []
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€æ–°300ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
        recent_csv = csv_files[-300:] if len(csv_files) > 300 else csv_files[-100:]
        
        for file in recent_csv:
            try:
                df = pd.read_csv(file)
                all_dfs.append(df)
            except Exception as e:
                print(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file}: {e}")
                continue
        
        # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        for file in latest_files:
            try:
                df = pd.read_csv(file)
                # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã«ã¯çµæœãŒãªã„ã®ã§ã€ã‚µãƒ³ãƒ—ãƒ«çµæœã‚’ä»˜ä¸
                if 'result' not in df.columns:
                    df['result'] = '01'  # æš«å®šçš„ã«1ç€ã¨ã™ã‚‹
                all_dfs.append(df)
                print(f"æœ€æ–°ãƒ‡ãƒ¼ã‚¿è¿½åŠ : {file}")
            except Exception as e:
                print(f"æœ€æ–°ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file}: {e}")
                continue
        
        if not all_dfs:
            print("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return None, None
            
        # çµ±åˆ
        combined_data = pd.concat(all_dfs, ignore_index=True)
        print(f"çµ±åˆå¾Œãƒ‡ãƒ¼ã‚¿æ•°: {len(combined_data)}")
        
        return self.prepare_enhanced_features(combined_data)
    
    def prepare_enhanced_features(self, data):
        """æ‹¡å¼µã•ã‚ŒãŸç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"""
        print("æ‹¡å¼µç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–‹å§‹...")
        
        # åŸºæœ¬å‰å‡¦ç†
        data = data.dropna(subset=['result'])
        
        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°
        data['is_winner'] = (data['result'] == '01').astype(int)
        
        features = []
        
        # === åŸºæœ¬ç‰¹å¾´é‡ ===
        basic_features = ['number', 'age', 'weight']
        for col in basic_features:
            if col in data.columns:
                data[col] = pd.to_numeric(data[col], errors='coerce').fillna(
                    {'number': 1, 'age': 30, 'weight': 52}[col]
                )
                features.append(col)
        
        # === æˆç¸¾é–¢é€£ç‰¹å¾´é‡ ===
        performance_cols = ['win_all', 'sec_all', 'win_cur', 'sec_cur']
        for col in performance_cols:
            if col in data.columns:
                data[col] = pd.to_numeric(data[col], errors='coerce').fillna(0)
                features.append(col)
        
        # === æ©Ÿæç‰¹å¾´é‡ ===
        equipment_cols = ['motor_ratio', 'boat_ratio']
        for col in equipment_cols:
            if col in data.columns:
                data[col] = pd.to_numeric(data[col], errors='coerce').fillna(50.0)
                features.append(col)
        
        # === å ´ãƒ»ãƒ¬ãƒ¼ã‚¹ç‰¹å¾´é‡ ===
        if 'placeid' in data.columns:
            data['placeid'] = pd.to_numeric(data['placeid'], errors='coerce').fillna(1)
            features.append('placeid')
            
        if 'racenumber' in data.columns:
            data['racenumber'] = pd.to_numeric(data['racenumber'], errors='coerce').fillna(1)
            features.append('racenumber')
        
        # === ãƒ©ãƒ³ã‚¯ç‰¹å¾´é‡ ===
        if 'rank' in data.columns:
            le = LabelEncoder()
            data['rank_encoded'] = le.fit_transform(data['rank'].astype(str).fillna('B1'))
            features.append('rank_encoded')
        
        # === å­£ç¯€æˆç¸¾ç‰¹å¾´é‡ ===
        season_cols = [f'r{i}' for i in range(1, 7)]
        for col in season_cols:
            if col in data.columns:
                data[col] = pd.to_numeric(data[col], errors='coerce').fillna(0)
                features.append(col)
        
        # === æ´¾ç”Ÿç‰¹å¾´é‡ï¼ˆæ‹¡å¼µç‰ˆï¼‰ ===
        
        # 1. ç·åˆæˆç¸¾
        if 'win_all' in data.columns and 'sec_all' in data.columns:
            data['total_performance'] = data['win_all'] + data['sec_all']
            features.append('total_performance')
        
        # 2. æ©Ÿæç·åˆåŠ›
        if 'motor_ratio' in data.columns and 'boat_ratio' in data.columns:
            data['equipment_power'] = (data['motor_ratio'] + data['boat_ratio']) / 2
            data['equipment_diff'] = data['motor_ratio'] - data['boat_ratio']
            features.extend(['equipment_power', 'equipment_diff'])
        
        # 3. å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—
        if 'age' in data.columns:
            data['age_group'] = pd.cut(data['age'], bins=[0, 25, 35, 45, 100], labels=[0, 1, 2, 3])
            data['age_group'] = data['age_group'].astype(int)
            features.append('age_group')
        
        # 4. ä½“é‡ã‚°ãƒ«ãƒ¼ãƒ—
        if 'weight' in data.columns:
            data['weight_group'] = pd.cut(data['weight'], bins=[0, 50, 53, 57, 100], labels=[0, 1, 2, 3])
            data['weight_group'] = data['weight_group'].astype(int)
            features.append('weight_group')
        
        # 5. ã‚³ãƒ¼ã‚¹ã®æœ‰åˆ©æ€§
        if 'number' in data.columns:
            # 1å·è‰‡ã¯æœ‰åˆ©
            data['is_course_1'] = (data['number'] == 1).astype(int)
            # ã‚¤ãƒ³ã‚³ãƒ¼ã‚¹ï¼ˆ1-3å·è‰‡ï¼‰
            data['is_inner'] = (data['number'] <= 3).astype(int)
            features.extend(['is_course_1', 'is_inner'])
        
        # 6. æœ€è¿‘ã®æˆç¸¾ãƒ‘ã‚¿ãƒ¼ãƒ³
        season_cols = [f'r{i}' for i in range(1, 7)]
        if all(col in data.columns for col in season_cols):
            # æœ€è¿‘ã®1ç€å›æ•°
            data['recent_wins'] = sum([(data[col] == 1).astype(int) for col in season_cols])
            # æœ€è¿‘ã®é€£å¯¾å›æ•°
            data['recent_places'] = sum([(data[col].isin([1, 2])).astype(int) for col in season_cols])
            # æœ€è¿‘ã®3ç€å†…å›æ•°
            data['recent_top3'] = sum([(data[col].isin([1, 2, 3])).astype(int) for col in season_cols])
            
            features.extend(['recent_wins', 'recent_places', 'recent_top3'])
        
        # 7. å ´ã®ç‰¹æ€§
        if 'placeid' in data.columns:
            # é›£æ°´é¢ï¼ˆæ±Ÿæˆ¸å·ã€å¹³å’Œå³¶ãªã©ï¼‰
            difficult_venues = [3, 4]  # æ±Ÿæˆ¸å·ã€å¹³å’Œå³¶
            data['is_difficult_venue'] = data['placeid'].isin(difficult_venues).astype(int)
            features.append('is_difficult_venue')
        
        # 8. ãƒ¬ãƒ¼ã‚¹æ™‚é–“å¸¯ã®ç‰¹æ€§
        if 'racenumber' in data.columns:
            # æ—©ã„æ™‚é–“ã®ãƒ¬ãƒ¼ã‚¹
            data['is_early_race'] = (data['racenumber'] <= 6).astype(int)
            # ãƒ¡ã‚¤ãƒ³ãƒ¬ãƒ¼ã‚¹ï¼ˆæœ€çµ‚3ãƒ¬ãƒ¼ã‚¹ï¼‰
            data['is_main_race'] = (data['racenumber'] >= 10).astype(int)
            features.extend(['is_early_race', 'is_main_race'])
        
        # === ç‰¹å¾´é‡ã®æ­£è¦åŒ–ãƒ»æ¨™æº–åŒ– ===
        continuous_features = ['win_all', 'sec_all', 'motor_ratio', 'boat_ratio', 
                              'total_performance', 'equipment_power']
        
        for col in continuous_features:
            if col in data.columns and col in features:
                # ç•°å¸¸å€¤ã‚’é™¤å»ï¼ˆ3Ïƒæ³•ï¼‰
                mean_val = data[col].mean()
                std_val = data[col].std()
                data[col] = data[col].clip(mean_val - 3*std_val, mean_val + 3*std_val)
        
        self.feature_names = features
        print(f"ä½¿ç”¨ç‰¹å¾´é‡æ•°: {len(features)}")
        print(f"ç‰¹å¾´é‡: {features}")
        
        # æœ€çµ‚ãƒ‡ãƒ¼ã‚¿æº–å‚™
        X = data[features].fillna(0)
        y = data['is_winner']
        
        print(f"æœ€çµ‚ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: X={X.shape}, y={y.shape}")
        print(f"1ç€ç‡: {y.mean():.3f}")
        print(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {data['date'].min() if 'date' in data.columns else 'ä¸æ˜'} - {data['date'].max() if 'date' in data.columns else 'ä¸æ˜'}")
        
        return X, y
    
    def train_advanced_models(self, X, y):
        """é«˜åº¦ãªãƒ¢ãƒ‡ãƒ«å­¦ç¿’"""
        print("\né«˜åº¦ãªãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...")
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {X_train.shape}")
        print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {X_test.shape}")
        
        # === 1. XGBoostï¼ˆæœ€é©åŒ–ç‰ˆï¼‰ ===
        print("\n1. XGBoostï¼ˆæœ€é©åŒ–ç‰ˆï¼‰å­¦ç¿’ä¸­...")
        xgb_model = xgb.XGBClassifier(
            n_estimators=300,
            max_depth=5,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.1,
            reg_lambda=0.1,
            random_state=42,
            eval_metric='auc',
            early_stopping_rounds=30
        )
        
        xgb_model.fit(
            X_train, y_train,
            eval_set=[(X_test, y_test)],
            verbose=False
        )
        
        self.models['XGBoost_Advanced'] = xgb_model
        self.feature_importance['XGBoost_Advanced'] = xgb_model.feature_importances_
        
        # === 2. LightGBMï¼ˆæœ€é©åŒ–ç‰ˆï¼‰ ===
        print("2. LightGBMï¼ˆæœ€é©åŒ–ç‰ˆï¼‰å­¦ç¿’ä¸­...")
        lgb_model = lgb.LGBMClassifier(
            n_estimators=300,
            max_depth=5,
            learning_rate=0.05,
            subsample=0.8,
            colsample_bytree=0.8,
            reg_alpha=0.1,
            reg_lambda=0.1,
            random_state=42,
            verbose=-1
        )
        
        lgb_model.fit(
            X_train, y_train,
            eval_set=[(X_test, y_test)],
            callbacks=[lgb.early_stopping(30), lgb.log_evaluation(0)]
        )
        
        self.models['LightGBM_Advanced'] = lgb_model
        self.feature_importance['LightGBM_Advanced'] = lgb_model.feature_importances_
        
        # === 3. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ« ===
        print("3. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ä½œæˆä¸­...")
        ensemble_predictions = (
            xgb_model.predict_proba(X_test)[:, 1] * 0.6 +
            lgb_model.predict_proba(X_test)[:, 1] * 0.4
        )
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµæœã‚’è©•ä¾¡
        ensemble_auc = roc_auc_score(y_test, ensemble_predictions)
        self.results['Ensemble'] = {
            'auc': ensemble_auc,
            'accuracy': accuracy_score(y_test, (ensemble_predictions > 0.5).astype(int))
        }
        
        # å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
        self.evaluate_models(X_test, y_test)
        
        return X_train, X_test, y_train, y_test
    
    def evaluate_models(self, X_test, y_test):
        """è©³ç´°ãªãƒ¢ãƒ‡ãƒ«è©•ä¾¡"""
        print("\n=== è©³ç´°ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ ===\n")
        
        for name, model in self.models.items():
            y_pred = model.predict(X_test)
            y_prob = model.predict_proba(X_test)[:, 1]
            
            accuracy = accuracy_score(y_test, y_pred)
            auc = roc_auc_score(y_test, y_prob)
            
            self.results[name] = {
                'accuracy': accuracy,
                'auc': auc
            }
            
            print(f"{name}:")
            print(f"  ç²¾åº¦: {accuracy:.4f}")
            print(f"  AUC: {auc:.4f}")
            
            # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
            print(f"  åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:")
            report = classification_report(y_test, y_pred, output_dict=True)
            print(f"    é©åˆç‡: {report['1']['precision']:.4f}")
            print(f"    å†ç¾ç‡: {report['1']['recall']:.4f}")
            print(f"    F1ã‚¹ã‚³ã‚¢: {report['1']['f1-score']:.4f}")
            print()
    
    def plot_feature_importance(self, X):
        """ç‰¹å¾´é‡é‡è¦åº¦ã®è©³ç´°å¯è¦–åŒ–"""
        plt.figure(figsize=(20, 12))
        
        n_models = len(self.feature_importance)
        
        for i, (name, importance) in enumerate(self.feature_importance.items()):
            plt.subplot(2, 2, i+1)
            
            feature_imp = pd.DataFrame({
                'feature': self.feature_names,
                'importance': importance
            }).sort_values('importance', ascending=False).head(15)
            
            sns.barplot(data=feature_imp, x='importance', y='feature')
            plt.title(f'{name} - Top 15 Features')
            plt.xlabel('Importance')
            
        plt.tight_layout()
        plt.savefig('latest_feature_importance.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # ç‰¹å¾´é‡é‡è¦åº¦ã®çµ±è¨ˆ
        print("\n=== ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ ===\n")
        importance_df = pd.DataFrame({
            name: imp for name, imp in self.feature_importance.items()
        }, index=self.feature_names)
        
        importance_df['å¹³å‡'] = importance_df.mean(axis=1)
        importance_df = importance_df.sort_values('å¹³å‡', ascending=False)
        
        print("Top 10 é‡è¦ç‰¹å¾´é‡:")
        print(importance_df.head(10).round(4))
    
    def get_best_model(self):
        """æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ"""
        if not self.results:
            return None, None
            
        # AUCã‚¹ã‚³ã‚¢ã§æ¯”è¼ƒ
        best_name = max(self.results.keys(), key=lambda k: self.results[k]['auc'])
        
        if best_name == 'Ensemble':
            print(f"\nğŸ† æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«: {best_name}")
            print(f"AUC: {self.results[best_name]['auc']:.4f}")
            return best_name, None  # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã¯ç‰¹åˆ¥å‡¦ç†
        else:
            best_model = self.models[best_name]
            print(f"\nğŸ† æœ€å„ªç§€ãƒ¢ãƒ‡ãƒ«: {best_name}")
            print(f"AUC: {self.results[best_name]['auc']:.4f}")
            print(f"ç²¾åº¦: {self.results[best_name]['accuracy']:.4f}")
            
            return best_name, best_model
    
    def save_model(self, model_name, model):
        """ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜"""
        if model is not None:
            model_file = f'latest_model_{model_name.lower().replace("_", "")}.pkl'
            joblib.dump(model, model_file)
            print(f"ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {model_file}")
            
            # ç‰¹å¾´é‡åã‚‚ä¿å­˜
            feature_file = f'latest_features_{model_name.lower().replace("_", "")}.pkl'
            joblib.dump(self.feature_names, feature_file)
            print(f"ç‰¹å¾´é‡ä¿å­˜: {feature_file}")
            
            return model_file
        return None

def main():
    print("ğŸš€ æœ€æ–°ãƒ‡ãƒ¼ã‚¿å¯¾å¿œæ©Ÿæ¢°å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
    print("=" * 50)
    
    system = LatestDataMLSystem()
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    X, y = system.load_all_data()
    if X is None:
        print("âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
    X_train, X_test, y_train, y_test = system.train_advanced_models(X, y)
    
    # ç‰¹å¾´é‡é‡è¦åº¦å¯è¦–åŒ–
    system.plot_feature_importance(X)
    
    # æœ€é©ãƒ¢ãƒ‡ãƒ«é¸æŠ
    best_name, best_model = system.get_best_model()
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    if best_model is not None:
        model_file = system.save_model(best_name, best_model)
    
    print("\nâœ… å­¦ç¿’å®Œäº†ï¼")
    print(f"ğŸ“Š ä½¿ç”¨ç‰¹å¾´é‡æ•°: {len(system.feature_names)}")
    print(f"ğŸ“ˆ æœ€é«˜AUC: {max(system.results.values(), key=lambda x: x['auc'])['auc']:.4f}")
    print(f"ğŸ’¾ ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«: {best_name}")

if __name__ == '__main__':
    main()